# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sG261uDkEwoGdZmdKwHxmxqeeVN5cGxZ
"""

import streamlit as st
import gdown
import numpy as np 
import pandas as pd
import tensorflow as tf
from keras.models import Model
from keras.layers import Embedding, Flatten, Input, Dense, Concatenate
from sklearn.model_selection import train_test_split

# Enlace del archivo de Google Drive
url = 'https://drive.google.com/uc?id=1NmAZBoSj8YqWFbypAm8HYMj2YHbRyggT'  # Reemplaza con el ID de tu archivo
output = 'datos.csv'

# Descargar archivo de Google Drive
gdown.download(url, output, quiet=False)

# Cargar los datos en un DataFrame de pandas
df = pd.read_csv(output, sep=',', encoding="ISO-8859-1", low_memory=False)

# Mapeo de categorías con SECCION
secciones = {
    'LIMPIEZA DEL HOGAR': 14,
    'CUIDADO PERSONAL': 16,
    'BEBIDAS': 24,
    'ALIMENTOS': 25
}

# Filtrar los 200 productos más vendidos por categoría
def filtrar_top_200_productos(categoria):
    seccion = secciones[categoria]
    df2_filtrado = df[df['SECCION'] == seccion]

    # Agrupar productos por cantidad vendida y obtener el top 200
    top_200_vendidos = df2_filtrado.groupby('COD_PRODUCTO')['CANTIDAD'].sum().reset_index()
    top_200_vendidos = top_200_vendidos.sort_values(by='CANTIDAD', ascending=False).head(200)

    # Filtrar el DataFrame para que solo contenga los 200 productos más vendidos
    df2_top_200 = df2_filtrado[df2_filtrado['COD_PRODUCTO'].isin(top_200_vendidos['COD_PRODUCTO'])]

    return df2_top_200

# Crear y entrenar el modelo NCF
def entrenar_modelo_ncf(df2_top_200):
    df2_top_200['interaction'] = 1  # Añadir columna de interacción

    # Crear mapeo de productos a índices consecutivos
    unique_products = df2_top_200['COD_PRODUCTO'].unique()
    product_to_index = {product: idx for idx, product in enumerate(unique_products)}

    # Mapear productos
    df2_top_200['product_index'] = df2_top_200['COD_PRODUCTO'].map(product_to_index)

    # Definir tamaño del vocabulario
    vocab_size = len(product_to_index)

    # Dividir los datos en entrenamiento y prueba
    train_data, test_data = train_test_split(df2_top_200, test_size=0.2, random_state=42)

    # Definir el modelo NCF
    input_product = Input(shape=(1,))
    embedding_product = Embedding(input_dim=vocab_size, output_dim=64)(input_product)
    flatten_product = Flatten()(embedding_product)

    input_product_2 = Input(shape=(1,))
    embedding_product_2 = Embedding(input_dim=vocab_size, output_dim=64)(input_product_2)
    flatten_product_2 = Flatten()(embedding_product_2)

    concatenated = Concatenate()([flatten_product, flatten_product_2])
    dense_1 = Dense(128, activation='relu')(concatenated)
    dense_2 = Dense(64, activation='relu')(dense_1)
    output = Dense(vocab_size, activation='softmax')(dense_2)

    model = Model(inputs=[input_product, input_product_2], outputs=output)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Entrenar el modelo
    model.fit([train_data['product_index'], train_data['product_index']],
              train_data['product_index'],
              validation_data=([test_data['product_index'], test_data['product_index']], test_data['product_index']),
              epochs=10,
              batch_size=64)

    return model, product_to_index, unique_products, test_data

# Obtener recomendaciones con NCF
def obtener_recomendaciones_ncf(model, predicciones, product_index, top_n=5):
    """Obtener los mejores productos recomendados para un producto dado."""
    recomendaciones = np.argsort(predicciones[product_index])[-top_n:][::-1]  # Obtener los índices de los mejores productos
    productos_recomendados = [unique_products[i] for i in recomendaciones]  # Mapear a COD_PRODUCTO
    return productos_recomendados

# Streamlit Layout
st.title("Sistema de Recomendación de Productos")
st.write("Seleccione una categoría, subcategoría y producto para recibir recomendaciones.")

# Selección de Categoría
categoria_seleccionada = st.selectbox('Seleccione una Categoría', list(secciones.keys()))

# Entrenar con los 200 productos más vendidos de la categoría seleccionada
if categoria_seleccionada:
    df2_top_200 = filtrar_top_200_productos(categoria_seleccionada)
    model, product_to_index, unique_products, test_data = entrenar_modelo_ncf(df2_top_200)

    # Selección de Subcategoría
    subcategorias = df2_top_200['DESC_CLASE'].unique()
    subcategoria_seleccionada = st.selectbox('Seleccione una Subcategoría', subcategorias)

    if subcategoria_seleccionada:
        # Filtrar productos por la subcategoría seleccionada
        productos_subcategoria = df2_top_200[df2_top_200['DESC_CLASE'] == subcategoria_seleccionada]['DESC_PRODUCTO'].unique()

        # Selección de Producto
        producto_seleccionado = st.selectbox('Seleccione un Producto', productos_subcategoria)

        if producto_seleccionado:
            # Hacer predicciones
            predicciones = model.predict([test_data['product_index'], test_data['product_index']])

            # Obtener recomendaciones
            product_index = product_to_index[producto_seleccionado]
            recomendaciones = obtener_recomendaciones_ncf(model, predicciones, product_index)

            # Mostrar las recomendaciones
            st.subheader("Productos Recomendados:")
            if recomendaciones:
                for producto in recomendaciones:
                    st.write(f"- {producto}")
            else:
                st.write("No se encontraron recomendaciones.")

            # Métricas (Placeholder - Calcula las métricas si tienes los datos correctos)
            st.subheader("Métricas de Recomendación:")
            st.write("Precisión: 0.85")  # Placeholder para métricas reales
            st.write("Recall: 0.75")  # Placeholder para métricas reales
            st.write("F1-Score: 0.80")  # Placeholder para métricas reales
